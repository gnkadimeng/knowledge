{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import uuid\n",
    "import json\n",
    "import ollama.client as client\n",
    "\n",
    "\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 800,\n",
    "    chunk_overlap  = 100,\n",
    "    length_function = len,\n",
    "    is_separator_regex = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters -> 277.456901 Mn\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "## Roberta based NER\n",
    "ner = pipeline(\"token-classification\", model=\"2rtl3/mn-xlm-roberta-base-named-entity\", aggregation_strategy=\"simple\")\n",
    "#ner = pipeline(\"token-classification\", model=\"dslim/bert-large-NER\", aggregation_strategy=\"simple\")\n",
    "\n",
    "\n",
    "print(\"Number of parameters ->\", ner.model.num_parameters()/1000000, \"Mn\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def row2NamedEntities(row):\n",
    "    # print(row)\n",
    "    ner_results = ner(row['text'])\n",
    "    metadata = {'chunk_id': row['chunk_id']}\n",
    "    entities = []\n",
    "    for result in ner_results:\n",
    "        entities = entities + [{'name': result['word'], 'entity': result['entity_group'], **metadata}]\n",
    "        \n",
    "    return entities\n",
    "\n",
    "def dfText2DfNE(dataframe):\n",
    "    ## Takes a dataframe from the parsed data and returns dataframe with named entities. \n",
    "    ## The input dataframe must have a text and a chunk_id column. \n",
    "\n",
    "    ## Using swifter for parallelism\n",
    "    ## 1. Calculate named entities for each row of the dataframe. \n",
    "    results = dataframe.apply(row2NamedEntities, axis=1)\n",
    "\n",
    "    ## Flatten the list of lists to one single list of entities. \n",
    "    entities_list = np.concatenate(results).ravel().tolist()\n",
    "\n",
    "    ## Remove all NaN entities\n",
    "    entities_dataframe = pd.DataFrame(entities_list).replace(' ', np.nan)\n",
    "    entities_dataframe = entities_dataframe.dropna(subset=['entity'])\n",
    "\n",
    "    ## Count the number of occurances per chunk id\n",
    "    entities_dataframe = entities_dataframe.groupby(['name', 'entity', 'chunk_id']).size().reset_index(name='count')\n",
    "\n",
    "    return entities_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks =  21\n",
      "Review\n",
      "\n",
      "Overview of the public and private health sectors\n",
      "\n",
      "The government-funded health sector, which is the provider of healthcare to vulnerable populations, has been chronically underfunded with 1.28% of the GDP. This translates to a healthcare expenditure of $2.7 per citizen per year. As a consequence, India has 0.7 public hospital beds per 100,000 people [2] now and 0.576 physicians per 1,000 population in 2000 [4], compared to the World Health Organization's recommended doctor-to-population ratio of 1:1,000 [5]. Since the inception of the National Health Mission (NHM) in 2005, the government has aimed to increase the quantum of services provided, but a lack of focus on quality has failed to make a dent in healthcare indicators [6]. At best, 37% of the population had any health insurance coverage in 2018 [7].\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "## Temp chunk to use the same loader \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from langchain.document_loaders import PyPDFLoader, UnstructuredPDFLoader, PyPDFium2Loader\n",
    "from langchain.document_loaders import PyPDFDirectoryLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path\n",
    "import random\n",
    "\n",
    "# ## Input data directory\n",
    "data_dir = \"cureus\"\n",
    "inputdirectory = Path(f\"./data_input/{data_dir}\")\n",
    "# ## This is where the output csv files will be written\n",
    "out_dir = data_dir\n",
    "outputdirectory = Path(f\"./data_output/{out_dir}\")\n",
    "\n",
    "\n",
    "## Dir PDF Loader\n",
    "#loader = PyPDFDirectoryLoader(inputdirectory)\n",
    "## File Loader\n",
    "#loader = PyPDFLoader(\"./data/MedicalDocuments/orf-path_health-n1.pdf\")\n",
    "loader = DirectoryLoader(inputdirectory, show_progress=True)\n",
    "documents = loader.load()\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1500,\n",
    "    chunk_overlap=150,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "\n",
    "pages = splitter.split_documents(documents)\n",
    "print(\"Number of chunks = \", len(pages))\n",
    "print(pages[3].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# #loader = PyPDFLoader(\"./data/GlobalPublicHealth2022.pdf\")\n",
    "# loader = PyPDFDirectoryLoader(\"./data/kesy1dd\")\n",
    "loader = DirectoryLoader(inputdirectory, show_progress=True)\n",
    "pages = loader.load_and_split(text_splitter=splitter)\n",
    "len(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rows = []\n",
    "for page in pages:\n",
    "    row = {'text': page.page_content, **page.metadata, 'chunk_id': uuid.uuid4().hex}\n",
    "    rows += [row]\n",
    "\n",
    "df = pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfne = dfText2DfNE(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>name</th>\n",
       "      <th>entity</th>\n",
       "      <th>count</th>\n",
       "      <th>chunk_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>India</td>\n",
       "      <td>LOC</td>\n",
       "      <td>30</td>\n",
       "      <td>00234c790deb443d80e70b2e2317a99c,0271cd9765f84...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>ASHAs</td>\n",
       "      <td>MISC</td>\n",
       "      <td>5</td>\n",
       "      <td>040cfeb81a1e4c56b6a194f433df9ecf,aee27861364c4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>COVID-19</td>\n",
       "      <td>MISC</td>\n",
       "      <td>4</td>\n",
       "      <td>1e19b3ed270d4e58a1e3c631c2106a78,aee27861364c4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>National Medical Council</td>\n",
       "      <td>ORG</td>\n",
       "      <td>4</td>\n",
       "      <td>010055a5231246e2a66f85ac6479d836,df327e30f04e4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>ANMs</td>\n",
       "      <td>MISC</td>\n",
       "      <td>3</td>\n",
       "      <td>040cfeb81a1e4c56b6a194f433df9ecf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>36</td>\n",
       "      <td>Nottingham</td>\n",
       "      <td>LOC</td>\n",
       "      <td>1</td>\n",
       "      <td>a78edd364a4e46d8ae611114241959c4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>1</td>\n",
       "      <td>-Income Count</td>\n",
       "      <td>MISC</td>\n",
       "      <td>1</td>\n",
       "      <td>1e19b3ed270d4e58a1e3c631c2106a78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>38</td>\n",
       "      <td>Online Training Management Information Systems</td>\n",
       "      <td>MISC</td>\n",
       "      <td>1</td>\n",
       "      <td>636c8a5239374716bcae64548e066470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>39</td>\n",
       "      <td>Out-Of-Pocket (OOP)</td>\n",
       "      <td>MISC</td>\n",
       "      <td>1</td>\n",
       "      <td>5de6b6a64ae649ad9c93f5a39b0c0675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>73</td>\n",
       "      <td>the World Health Organization</td>\n",
       "      <td>ORG</td>\n",
       "      <td>1</td>\n",
       "      <td>cc1c7ce5087a49b9bec2e3ecbc6e9fab</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index                                            name entity  count  \\\n",
       "0      25                                           India    LOC     30   \n",
       "1       4                                           ASHAs   MISC      5   \n",
       "2      13                                        COVID-19   MISC      4   \n",
       "3      34                        National Medical Council    ORG      4   \n",
       "4       3                                            ANMs   MISC      3   \n",
       "..    ...                                             ...    ...    ...   \n",
       "69     36                                      Nottingham    LOC      1   \n",
       "70      1                                   -Income Count   MISC      1   \n",
       "71     38  Online Training Management Information Systems   MISC      1   \n",
       "72     39                             Out-Of-Pocket (OOP)   MISC      1   \n",
       "73     73                   the World Health Organization    ORG      1   \n",
       "\n",
       "                                             chunk_id  \n",
       "0   00234c790deb443d80e70b2e2317a99c,0271cd9765f84...  \n",
       "1   040cfeb81a1e4c56b6a194f433df9ecf,aee27861364c4...  \n",
       "2   1e19b3ed270d4e58a1e3c631c2106a78,aee27861364c4...  \n",
       "3   010055a5231246e2a66f85ac6479d836,df327e30f04e4...  \n",
       "4                    040cfeb81a1e4c56b6a194f433df9ecf  \n",
       "..                                                ...  \n",
       "69                   a78edd364a4e46d8ae611114241959c4  \n",
       "70                   1e19b3ed270d4e58a1e3c631c2106a78  \n",
       "71                   636c8a5239374716bcae64548e066470  \n",
       "72                   5de6b6a64ae649ad9c93f5a39b0c0675  \n",
       "73                   cc1c7ce5087a49b9bec2e3ecbc6e9fab  \n",
       "\n",
       "[74 rows x 5 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ne = dfne.groupby(['name', 'entity']).agg({'count': 'sum', 'chunk_id': ','.join}).reset_index()\n",
    "df_ne.sort_values(by='count', ascending=False).head(100).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Improve Efficiency\\n\\nThe public health system is currently unable to utilize even the 1% of the GDP that has traditionally been available to it. With a doubling of the federal government’s allocation in 2022, its capacity to do so must be increased. Increasing the financial allocation and its utilization capacity will enhance the health infrastructure and workforce capability. This requires institutional capacity building and competency-based training in the government healthcare system [37]. This will allow the country to align its health services to local priorities as India exhibits its diversity in its population and disease profiles. The recently started National Health Protection Mission has limited uptake The majority of Indians (up to 80.9% in urban\\n\\nand 85.9% in rural) still do not have health insurance [38].\\n\\nAccredit Health Facilities and in Practice Regulate the Private Health Sector\\n\\nThe public health sector has revised standards [39] for healthcare infrastructure, personnel, equipment and services for primary, secondary and tertiary care. They need to be utilized to accredit health facilities in'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[12].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def extractConcepts(prompt: str, model='mistral-openorca:latest'):\n",
    "    SYS_PROMPT = (\n",
    "        \"Your task is to extract the key entities mentioned in the users input.\\n\"\n",
    "        \"Entities may include - event, concept, person, place, object, document, organisation, artifact, misc, etc.\\n\"\n",
    "        \"Format your output as a list of json with the following structure.\\n\"\n",
    "        \"[{\\n\"\n",
    "        \"   \\\"entity\\\": The Entity string\\n\"\n",
    "        \"   \\\"importance\\\": How important is the entity given the context on a scale of 1 to 5, 5 being the highest.\\n\"\n",
    "        \"   \\\"type\\\": Type of entity\\n\"\n",
    "        \"}, { }]\"\n",
    "    )\n",
    "    response, context = client.generate(model_name=model, system=SYS_PROMPT, prompt=prompt)\n",
    "    return json.loads(response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "the JSON object must be str, bytes or bytearray, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m res \u001b[38;5;241m=\u001b[39m extractConcepts(prompt \u001b[38;5;241m=\u001b[39m pages[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpage_content)\n",
      "Cell \u001b[0;32mIn[46], line 13\u001b[0m, in \u001b[0;36mextractConcepts\u001b[0;34m(prompt, model)\u001b[0m\n\u001b[1;32m      2\u001b[0m SYS_PROMPT \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYour task is to extract the key entities mentioned in the users input.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntities may include - event, concept, person, place, object, document, organisation, artifact, misc, etc.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}, \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m }]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     12\u001b[0m response, context \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mgenerate(model_name\u001b[38;5;241m=\u001b[39mmodel, system\u001b[38;5;241m=\u001b[39mSYS_PROMPT, prompt\u001b[38;5;241m=\u001b[39mprompt)\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m json\u001b[38;5;241m.\u001b[39mloads(response)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/json/__init__.py:339\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    338\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(s, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mbytearray\u001b[39m)):\n\u001b[0;32m--> 339\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe JSON object must be str, bytes or bytearray, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    340\u001b[0m                         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{\u001b[39;00ms\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n",
      "\u001b[0;31mTypeError\u001b[0m: the JSON object must be str, bytes or bytearray, not NoneType"
     ]
    }
   ],
   "source": [
    "res = extractConcepts(prompt = pages[1].page_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'entity': 'infectious diseases', 'importance': 4},\n",
       " {'entity': 'disasters', 'importance': 3},\n",
       " {'entity': 'EMS', 'importance': 3},\n",
       " {'entity': 'RRA reports', 'importance': 2},\n",
       " {'entity': 'EIS bulletins', 'importance': 1.5},\n",
       " {'entity': 'DON reports', 'importance': 1},\n",
       " {'entity': 'WHO Regions', 'importance': 2},\n",
       " {'entity': 'IHR (2005) framework', 'importance': 3}]"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
