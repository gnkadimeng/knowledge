{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Network Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading previously calculated dataframes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data_output/MediumArticles/chunks.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m dataframe_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMediumArticles\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data_output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataframe_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/chunks.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m df_concepts \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./data_output/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataframe_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/concepts.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_concepts\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    900\u001b[0m     dialect,\n\u001b[1;32m    901\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m    909\u001b[0m )\n\u001b[1;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1662\u001b[0m     f,\n\u001b[1;32m   1663\u001b[0m     mode,\n\u001b[1;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1670\u001b[0m )\n\u001b[1;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    860\u001b[0m             handle,\n\u001b[1;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    865\u001b[0m         )\n\u001b[1;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data_output/MediumArticles/chunks.csv'"
     ]
    }
   ],
   "source": [
    "dataframe_dir = \"MediumArticles\"\n",
    "df = pd.read_csv(f\"./data_output/{dataframe_dir}/chunks.csv\", sep=\"|\")\n",
    "df_concepts = pd.read_csv(f\"./data_output/{dataframe_dir}/concepts.csv\", sep=\"|\")\n",
    "print(df_concepts.shape)\n",
    "df_concepts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Graph Dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph dataframe is a dataframe where every row is a connection between two nodes.\n",
    "\n",
    "It is basically an inner self join of the nodes dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes =  2570\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>entity_L</th>\n",
       "      <th>importance_L</th>\n",
       "      <th>category_L</th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>type_L</th>\n",
       "      <th>entity_R</th>\n",
       "      <th>importance_R</th>\n",
       "      <th>category_R</th>\n",
       "      <th>type_R</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>interoperability</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "      <td>bb894d4a987241c6b7827d4acabac6dc</td>\n",
       "      <td>concept</td>\n",
       "      <td>introduction</td>\n",
       "      <td>3</td>\n",
       "      <td>event</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>introduction</td>\n",
       "      <td>3</td>\n",
       "      <td>event</td>\n",
       "      <td>bb894d4a987241c6b7827d4acabac6dc</td>\n",
       "      <td>concept</td>\n",
       "      <td>interoperability</td>\n",
       "      <td>5</td>\n",
       "      <td>concept</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>unique charging port design</td>\n",
       "      <td>4</td>\n",
       "      <td>misc</td>\n",
       "      <td>ebcfb9727a42482d986fa2b0a64fa8ac</td>\n",
       "      <td>concept</td>\n",
       "      <td>usb c</td>\n",
       "      <td>5</td>\n",
       "      <td>object</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>unique charging port design</td>\n",
       "      <td>4</td>\n",
       "      <td>misc</td>\n",
       "      <td>ebcfb9727a42482d986fa2b0a64fa8ac</td>\n",
       "      <td>concept</td>\n",
       "      <td>mobile phone model</td>\n",
       "      <td>3</td>\n",
       "      <td>object</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>unique charging port design</td>\n",
       "      <td>4</td>\n",
       "      <td>misc</td>\n",
       "      <td>ebcfb9727a42482d986fa2b0a64fa8ac</td>\n",
       "      <td>concept</td>\n",
       "      <td>phone companies</td>\n",
       "      <td>4</td>\n",
       "      <td>organisation</td>\n",
       "      <td>concept</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                     entity_L  importance_L category_L  \\\n",
       "0      1             interoperability             5    concept   \n",
       "1      2                 introduction             3      event   \n",
       "2      5  unique charging port design             4       misc   \n",
       "3      6  unique charging port design             4       misc   \n",
       "4      7  unique charging port design             4       misc   \n",
       "\n",
       "                           chunk_id   type_L            entity_R  \\\n",
       "0  bb894d4a987241c6b7827d4acabac6dc  concept        introduction   \n",
       "1  bb894d4a987241c6b7827d4acabac6dc  concept    interoperability   \n",
       "2  ebcfb9727a42482d986fa2b0a64fa8ac  concept               usb c   \n",
       "3  ebcfb9727a42482d986fa2b0a64fa8ac  concept  mobile phone model   \n",
       "4  ebcfb9727a42482d986fa2b0a64fa8ac  concept     phone companies   \n",
       "\n",
       "   importance_R    category_R   type_R  \n",
       "0             3         event  concept  \n",
       "1             5       concept  concept  \n",
       "2             5        object  concept  \n",
       "3             3        object  concept  \n",
       "4             4  organisation  concept  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfne_join = pd.merge(\n",
    "    df_concepts, df_concepts, how=\"inner\", on=\"chunk_id\", suffixes=(\"_L\", \"_R\")\n",
    ")\n",
    "\n",
    "## Remove self Loops\n",
    "self_loops_drop = dfne_join[dfne_join[\"entity_L\"] == dfne_join[\"entity_R\"]].index\n",
    "dfg = dfne_join.drop(index=self_loops_drop).reset_index()\n",
    "\n",
    "## This is our graph dataframe\n",
    "print(\"Total number of nodes = \", dfg.shape[0])\n",
    "dfg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the graph dataframe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original graph dataframe is too big to visualise. So we will make another dataframe for visualisation purpose.\n",
    "\n",
    "-   remove the less important nodes\n",
    "-   remove less important edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Less important Nodes =  29 \n",
      "Less Important Edges =  2\n"
     ]
    }
   ],
   "source": [
    "## Drop nodes which are less important\n",
    "less_important_nodes = dfg[(dfg[\"importance_L\"] < 2)].index\n",
    "## Drop edges where both the nodes are less important than 5\n",
    "less_important_edges = dfg[(dfg[\"importance_L\"] < 2) & (dfg[\"importance_R\"] < 2)].index\n",
    "drops = less_important_nodes.union(less_important_edges)\n",
    "\n",
    "print(\n",
    "    \"Less important Nodes = \",\n",
    "    less_important_nodes.shape[0],\n",
    "    \"\\nLess Important Edges = \",\n",
    "    less_important_edges.shape[0],\n",
    ")\n",
    "\n",
    "## Remove these rows from the graph dataframe\n",
    "dfg_vis = dfg.drop(index=drops).reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine similar edges\n",
    "\n",
    "Group the edges between the same nodes and combine them into single edge with its weight equal to the count. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Number of Edges in the Visualisation Graph =  2481\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_L</th>\n",
       "      <th>entity_R</th>\n",
       "      <th>importance_L</th>\n",
       "      <th>importance_R</th>\n",
       "      <th>chunks</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>35200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>35209</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>99def</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>adt_a01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>al</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity_L entity_R  importance_L  importance_R  \\\n",
       "0  10000 w 100th ave    35200           2.0           2.0   \n",
       "1  10000 w 100th ave    35209           2.0           2.0   \n",
       "2  10000 w 100th ave    99def           2.0           2.0   \n",
       "3  10000 w 100th ave  adt_a01           2.0           2.0   \n",
       "4  10000 w 100th ave       al           2.0           2.0   \n",
       "\n",
       "                             chunks  count  \n",
       "0  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "1  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "2  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "3  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "4  45a6201014f84cc7bcb7aea24a7f7af6      1  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "## Group and aggregate edges.\n",
    "dfg_vis = (\n",
    "    dfg_vis.groupby([\"entity_L\", \"entity_R\"])\n",
    "    .agg(\n",
    "        {\n",
    "            \"importance_L\": \"mean\",\n",
    "            \"importance_R\": \"mean\",\n",
    "            \"chunk_id\": [\",\".join, \"count\"],\n",
    "        }\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "dfg_vis.columns = [\n",
    "    \"entity_L\",\n",
    "    \"entity_R\",\n",
    "    \"importance_L\",\n",
    "    \"importance_R\",\n",
    "    \"chunks\",\n",
    "    \"count\",\n",
    "]\n",
    "\n",
    "print(\"Final Number of Edges in the Visualisation Graph = \", dfg_vis.shape[0])\n",
    "dfg_vis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing overconnected nodes\n",
    "\n",
    "These are featured in the header and the footer of the pdf file, so they are a little too connected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Number of Edges  =  2481 \n",
      "Dropped edges: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_L</th>\n",
       "      <th>entity_R</th>\n",
       "      <th>importance_L</th>\n",
       "      <th>importance_R</th>\n",
       "      <th>chunks</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>35200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>35209</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>99def</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>adt_a01</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>al</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>45a6201014f84cc7bcb7aea24a7f7af6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            entity_L entity_R  importance_L  importance_R  \\\n",
       "0  10000 w 100th ave    35200           2.0           2.0   \n",
       "1  10000 w 100th ave    35209           2.0           2.0   \n",
       "2  10000 w 100th ave    99def           2.0           2.0   \n",
       "3  10000 w 100th ave  adt_a01           2.0           2.0   \n",
       "4  10000 w 100th ave       al           2.0           2.0   \n",
       "\n",
       "                             chunks  count  \n",
       "0  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "1  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "2  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "3  45a6201014f84cc7bcb7aea24a7f7af6      1  \n",
       "4  45a6201014f84cc7bcb7aea24a7f7af6      1  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind = dfg_vis[\n",
    "    dfg_vis[\"entity_L\"].isin(\n",
    "        [\"Pathways to Health Equity for the G20\", \"Accelerating Global Health\"]\n",
    "    )\n",
    "    | dfg_vis[\"entity_R\"].isin(\n",
    "        [\"Pathways to Health Equity for the G20\", \"Accelerating Global Health\"]\n",
    "    )\n",
    "].index\n",
    "dfg_vis.drop(index=ind, axis=1, inplace=True)\n",
    "print(\"Final Number of Edges  = \", dfg_vis.shape[0], \"\\nDropped edges:\", len(ind))\n",
    "dfg_vis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a NetworkX Graph\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate nodes\n",
    "\n",
    "Here I am grouping the graph dataframe by left node and calculating the mean importance. This way we will end up with only the unique nodes from the graph dataframe along with their weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_L</th>\n",
       "      <th>importance_L</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30-year-old standard</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35200</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35209</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entity_L  importance_L\n",
       "0     10000 w 100th ave           2.0\n",
       "1                  2010           4.0\n",
       "2  30-year-old standard           4.0\n",
       "3                 35200           2.0\n",
       "4                 35209           2.0"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nodes = df_graph[\"entity_L\"].unique()\n",
    "nodes = dfg_vis.groupby([\"entity_L\"]).agg({\"importance_L\": \"mean\"}).reset_index()\n",
    "nodes.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build a NetworkX object with nodes and edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "for index, row in nodes.iterrows():\n",
    "    G.add_node(row[\"entity_L\"])\n",
    "\n",
    "for index, row in dfg_vis.iterrows():\n",
    "    G.add_edge(str(row[\"entity_L\"]), str(row[\"entity_R\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Community Detection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect communities using the Girvan Newman algorithm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Communities =  27\n"
     ]
    }
   ],
   "source": [
    "communities_generator = nx.community.girvan_newman(G)\n",
    "top_level_communities = next(communities_generator)\n",
    "next_level_communities = next(communities_generator)\n",
    "communities = sorted(map(sorted, next_level_communities))\n",
    "print(\"Number of Communities = \", len(communities))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add colors to nodes based on community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_L</th>\n",
       "      <th>importance_L</th>\n",
       "      <th>color</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000 w 100th ave</td>\n",
       "      <td>2.0</td>\n",
       "      <td>#db576c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010</td>\n",
       "      <td>4.0</td>\n",
       "      <td>#db578a</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30-year-old standard</td>\n",
       "      <td>4.0</td>\n",
       "      <td>#db57a7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35200</td>\n",
       "      <td>2.0</td>\n",
       "      <td>#db576c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35209</td>\n",
       "      <td>2.0</td>\n",
       "      <td>#db576c</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               entity_L  importance_L    color  group\n",
       "0     10000 w 100th ave           2.0  #db576c      1\n",
       "1                  2010           4.0  #db578a      2\n",
       "2  30-year-old standard           4.0  #db57a7      3\n",
       "3                 35200           2.0  #db576c      1\n",
       "4                 35209           2.0  #db576c      1"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palette = \"hls\"\n",
    "\n",
    "\n",
    "## Now add these colors to communities and make another dataframe\n",
    "def colors2Community(communities) -> pd.DataFrame:\n",
    "    ## Define a color palette\n",
    "    p = sns.color_palette(palette, len(communities)).as_hex()\n",
    "    rows = []\n",
    "    group = 0\n",
    "    for community in communities:\n",
    "        color = p.pop()\n",
    "        group += 1\n",
    "        for node in community:\n",
    "            rows += [{\"entity_L\": node, \"color\": color, \"group\": group}]\n",
    "    df_colors = pd.DataFrame(rows)\n",
    "    return df_colors\n",
    "\n",
    "\n",
    "colors = colors2Community(communities)\n",
    "\n",
    "df_nodes_colors = pd.merge(\n",
    "    nodes, colors, how=\"left\", on=\"entity_L\", suffixes=(\"_N\", \"_C\")\n",
    ")\n",
    "# nodes.head()\n",
    "df_nodes_colors.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a nodes dataframe with colors and sizes of each node.\n",
    "\n",
    "lets recreate our graph.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()\n",
    "node_size_multiple = 6\n",
    "\n",
    "for index, row in df_nodes_colors.iterrows():\n",
    "    G.add_node(\n",
    "        row[\"entity_L\"],\n",
    "        size=row[\"importance_L\"] * node_size_multiple,\n",
    "        title=row[\"entity_L\"],\n",
    "        color=row[\"color\"],\n",
    "    )\n",
    "\n",
    "for index, row in dfg_vis.iterrows():\n",
    "    G.add_edge(\n",
    "        str(row[\"entity_L\"]),\n",
    "        str(row[\"entity_R\"]),\n",
    "        weight=row[\"count\"],\n",
    "        name=row[\"chunks\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./docs/index.html\n"
     ]
    }
   ],
   "source": [
    "graph_output_directory = \"./docs/index.html\"\n",
    "\n",
    "net = Network(\n",
    "    notebook=False,\n",
    "    bgcolor=\"#1a1a1a\",\n",
    "    cdn_resources=\"remote\",\n",
    "    height=\"900px\",\n",
    "    width=\"100%\",\n",
    "    select_menu=True,\n",
    "    font_color=\"#cccccc\",\n",
    "    # filter_menu=True,\n",
    ")\n",
    "\n",
    "net.from_nx(G)\n",
    "net.repulsion(node_distance=150, spring_length=400)\n",
    "# net.barnes_hut(gravity=-18100, central_gravity=5.05, spring_length=380)\n",
    "net.show_buttons(filter_=[\"physics\"])\n",
    "\n",
    "net.show(graph_output_directory, notebook=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
